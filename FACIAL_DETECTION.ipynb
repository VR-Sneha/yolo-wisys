{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "dQ12AW11xZwx",
        "outputId": "062af52c-f710-4ba0-98fb-b203285651de"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'for' statement on line 12 (<ipython-input-4-d363b5de3dda>, line 14)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-d363b5de3dda>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    name = imagePath.split(os.path.sep)[-2]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 12\n"
          ]
        }
      ],
      "source": [
        "from imutils import paths\n",
        "import face_recognition\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "#get paths of each file in folder named Images\n",
        "#Images here contains my data(folders of various persons)\n",
        "imagePaths = list(paths.list_images('Images'))\n",
        "knownEncodings = []\n",
        "knownNames = []\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "# extract the person name from the image path\n",
        "name = imagePath.split(os.path.sep)[-2]\n",
        "# load the input image and convert it from BGR (OpenCV ordering)\n",
        "# to dlib ordering (RGB)\n",
        "image = cv2.imread(imagePath)\n",
        "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#Use Face_recognition to locate faces\n",
        "boxes = face_recognition.face_locations(rgb,model='hog')\n",
        "# compute the facial embedding for the face\n",
        "encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "# loop over the encodings\n",
        "for encoding in encodings:\n",
        "knownEncodings.append(encoding)\n",
        "knownNames.append(name)\n",
        "#save emcodings along with their names in dictionary data\n",
        "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
        "#use pickle to save data into a file for later use\n",
        "f = open(\"face_enc\", \"wb\")\n",
        "f.write(pickle.dumps(data))\n",
        "f.close()\n",
        "#FACE REGAGNITION LIVE WEBCAM\n",
        "import face_recognition\n",
        "import imutils\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "#find path of xml file containing haarcascade file\n",
        "cascPathface = os.path.dirname(\n",
        "cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
        "# load the harcaascade in the cascade classifier\n",
        "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
        "# load the known faces and embeddings saved in last file\n",
        "data = pickle.loads(open('face_enc', \"rb\").read())\n",
        "print(\"Streaming started\")\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "# loop over frames from the video file stream\n",
        "while True:\n",
        "# grab the frame from the threaded video stream\n",
        "ret, frame = video_capture.read()\n",
        "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "faces = faceCascade.detectMultiScale(gray,\n",
        "scaleFactor=1.1,\n",
        "minNeighbors=5,\n",
        "minSize=(60, 60),\n",
        "flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "# convert the input frame from BGR to RGB\n",
        "rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "# the facial embeddings for face in input\n",
        "encodings = face_recognition.face_encodings(rgb)\n",
        "names = []\n",
        "# loop over the facial embeddings incase\n",
        "# we have multiple embeddings for multiple fcaes\n",
        "for encoding in encodings:\n",
        "#Compare encodings with encodings in data[\"encodings\"]\n",
        "#Matches contain array with boolean values and True for the embeddings it matches\n",
        "closely\n",
        "#and False for rest\n",
        "matches = face_recognition.compare_faces(data[\"encodings\"],\n",
        "encoding)\n",
        "#set name =inknown if no encoding matches\n",
        "name = \"Unknown\"\n",
        "# check to see if we have found a match\n",
        "if True in matches:\n",
        "#Find positions at which we get True and store them\n",
        "matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "counts = {}\n",
        "# loop over the matched indexes and maintain a count for\n",
        "# each recognized face face\n",
        "for i in matchedIdxs:\n",
        "#Check the names at respective indexes we stored in matchedIdxs\n",
        "name = data[\"names\"][i]\n",
        "#increase count for the name we got\n",
        "counts[name] = counts.get(name, 0) + 1\n",
        "#set name which has highest count\n",
        "name = max(counts, key=counts.get)\n",
        "# update the list of names\n",
        "names.append(name)\n",
        "# loop over the recognized faces\n",
        "for ((x, y, w, h), name) in zip(faces, names):\n",
        "# rescale the face coordinates\n",
        "# draw the predicted face name on the image\n",
        "cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "cv2.putText(frame, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "0.75, (0, 255, 0), 2)\n",
        "cv2.imshow(\"Frame\", frame)\n",
        "if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "break\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n",
        "#Face Recognition in Images\n",
        "import face_recognition\n",
        "import imutils\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "#find path of xml file containing haarcascade file\n",
        "cascPathface = os.path.dirname(\n",
        "cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
        "# load the harcaascade in the cascade classifier\n",
        "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
        "# load the known faces and embeddings saved in last file\n",
        "data = pickle.loads(open('face_enc', \"rb\").read())\n",
        "#Find path to the image you want to detect face and pass it here\n",
        "image = cv2.imread(Path-to-img)\n",
        "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#convert image to Greyscale for haarcascade\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "faces = faceCascade.detectMultiScale(gray,\n",
        "scaleFactor=1.1,\n",
        "minNeighbors=5,\n",
        "minSize=(60, 60),\n",
        "flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "# the facial embeddings for face in input\n",
        "encodings = face_recognition.face_encodings(rgb)\n",
        "names = []\n",
        "# loop over the facial embeddings incase\n",
        "# we have multiple embeddings for multiple fcaes\n",
        "for encoding in encodings:\n",
        "#Compare encodings with encodings in data[\"encodings\"]\n",
        "#Matches contain array with boolean values and True for the embeddings it matches\n",
        "closely\n",
        "#and False for rest\n",
        "matches = face_recognition.compare_faces(data[\"encodings\"],\n",
        "encoding)\n",
        "#set name =inknown if no encoding matches\n",
        "name = \"Unknown\"\n",
        "# check to see if we have found a match\n",
        "if True in matches:\n",
        "#Find positions at which we get True and store them\n",
        "matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "counts = {}\n",
        "# loop over the matched indexes and maintain a count for\n",
        "# each recognized face face\n",
        "for i in matchedIdxs:\n",
        "#Check the names at respective indexes we stored in matchedIdxs\n",
        "name = data[\"names\"][i]\n",
        "#increase count for the name we got\n",
        "counts[name] = counts.get(name, 0) + 1\n",
        "#set name which has highest count\n",
        "name = max(counts, key=counts.get)\n",
        "# update the list of names\n",
        "names.append(name)\n",
        "# loop over the recognized faces\n",
        "for ((x, y, w, h), name) in zip(faces, names):\n",
        "# rescale the face coordinates\n",
        "# draw the predicted face name on the image\n",
        "cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "cv2.putText(image, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "0.75, (0, 255, 0), 2)\n",
        "cv2.imshow(\"Frame\", image)\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jOtkusY4x88y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}